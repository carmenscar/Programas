{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COH-PIAH.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPqJWG7GeYLzcRc4VluxaT3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carmenscar/Jogo_do_nim/blob/master/COH_PIAH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZw0EF33nrUr"
      },
      "source": [
        "# Similaridade entre textos\n",
        "\n",
        "Exercício de conclusão de curso - introdução a ciência da computação com Python - parte 1\n",
        "\n",
        "## Introdução\n",
        "\n",
        "Manuel Estandarte é monitor na disciplina Introdução à Produção Textual I na Universidade de Pasárgada (UPA). Durante o período letivo, Manuel descobriu que uma epidemia de COH-PIAH estava se espalhando pela UPA. Essa doença rara e altamente contagiosa faz com que indivíduos contaminados produzam, involuntariamente, textos muito semelhantes aos de outras pessoas. Após a entrega da primeira redação, Manuel desconfiou que alguns alunos estavam sofrendo de COH-PIAH. Manuel, preocupado com a saúde da turma, resolveu buscar um método para identificar os casos de COH-PIAH. Para isso, ele necessita da sua ajuda para desenvolver um programa que o auxilie a identificar os alunos contaminados.\n",
        "\n",
        "## Detecção de autoria\n",
        "Diferentes pessoas possuem diferentes estilos de escrita; por exemplo, algumas pessoas preferem sentenças mais curtas, outras preferem sentenças mais longas. Utilizando diversas estatísticas do texto, é possível identificar aspectos que funcionam como uma “assinatura” do seu autor e, portanto, é possível detectar se dois textos dados foram escritos por uma mesma pessoa. Ou seja, essa “assinatura” pode ser utilizada para detecção de plágio, evidência forense ou, neste caso, para diagnosticar a grave doença COH-PIAH.\n",
        "\n",
        "## Traços linguísticos\n",
        "Neste exercício utilizaremos as seguintes estatísticas para detectar a doença:\n",
        "\n",
        "Tamanho médio de palavra: Média simples do número de caracteres por palavra.\n",
        "Relação Type-Token: Número de palavras diferentes utilizadas em um texto divididas pelo total de palavras.\n",
        "Razão Hapax Legomana: Número de palavras utilizadas uma única vez dividido pelo número total de palavras.\n",
        "Tamanho médio de sentença: Média simples do número de caracteres por sentença.\n",
        "Complexidade de sentença: Média simples do número de frases por sentença.\n",
        "Tamanho médio de frase: Média simples do número de caracteres por frase.\n",
        "## Funcionamento do programa\n",
        "A partir da assinatura conhecida de um portador de COH-PIAH, seu programa deverá receber diversos textos e calcular os valores dos diferentes traços linguísticos desses textos para compará-los com a assinatura dada. Os traços linguísticos que seu programa deve utilizar são calculados da seguinte forma:\n",
        "\n",
        "**Tamanho médio de palavra** é a soma dos tamanhos das palavras dividida pelo número total de palavras.\n",
        "\n",
        "**Relação Type-Token** é o número de palavras diferentes dividido pelo número total de palavras. \n",
        "\n",
        "**Razão Hapax Legomana** é o número de palavras que aparecem uma única vez dividido pelo total de palavras. \n",
        "\n",
        "**Tamanho médio de sentença** é a soma dos números de caracteres em todas as sentenças dividida pelo número de sentenças (os caracteres que separam uma sentença da outra não devem ser contabilizados como parte da sentença).\n",
        "\n",
        "**Complexidade de sentença** é o número total de frases divido pelo número de sentenças.\n",
        "\n",
        "**Tamanho médio de frase** é a soma do número de caracteres em cada frase dividida pelo número de frases no texto  (os caracteres que separam uma frase da outra não devem ser contabilizados como parte da frase).\n",
        "\n",
        "\n",
        "Após calcular esses valores para cada texto, você deve compará-los com a assinatura fornecida para os infectados por COH-PIAH. O grau de similaridade entre dois textos\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNOyPoe1pRId"
      },
      "source": [
        "import re\n",
        "\n",
        "def le_assinatura():\n",
        "\n",
        "    print(\"Bem-vindo ao detector automático de COH-PIAH.\")\n",
        "    print(\"Informe a assinatura típica de um aluno infectado:\")\n",
        "\n",
        "    wal = float(input(\"Entre o tamanho médio de palavra:\"))\n",
        "    ttr = float(input(\"Entre a relação Type-Token:\"))\n",
        "    hlr = float(input(\"Entre a Razão Hapax Legomana:\"))\n",
        "    sal = float(input(\"Entre o tamanho médio de sentença:\"))\n",
        "    sac = float(input(\"Entre a complexidade média da sentença:\"))\n",
        "    pal = float(input(\"Entre o tamanho medio de frase:\"))\n",
        "\n",
        "    return [wal, ttr, hlr, sal, sac, pal]\n",
        "\n",
        "def le_textos():\n",
        "\n",
        "    i = 1\n",
        "    textos = []\n",
        "    texto = input(\"Digite o texto \" + str(i) +\" (aperte enter para sair):\")\n",
        "    while texto:\n",
        "        textos.append(texto)\n",
        "        i += 1\n",
        "        texto = input(\"Digite o texto \" + str(i) +\" (aperte enter para sair):\")\n",
        "\n",
        "    return textos\n",
        "\n",
        "def separa_sentencas(texto):\n",
        "\n",
        "    sentencas = re.split(r'[.!?]+', texto)\n",
        "    if sentencas[-1] == '':\n",
        "        del sentencas[-1]\n",
        "    return sentencas\n",
        "\n",
        "def separa_frases(sentenca):\n",
        "\n",
        "    return re.split(r'[,:;]+', sentenca)\n",
        "\n",
        "def separa_palavras(frase):\n",
        "\n",
        "    return frase.split()\n",
        "\n",
        "def n_palavras_unicas(nova_lista_palavras):\n",
        "\n",
        "    freq = dict()\n",
        "    unicas = 0\n",
        "    for palavra in nova_lista_palavras:\n",
        "        p = palavra.lower()\n",
        "        if p in freq:\n",
        "            if freq[p] == 1:\n",
        "                unicas -= 1\n",
        "            freq[p] += 1\n",
        "        else:\n",
        "            freq[p] = 1\n",
        "            unicas += 1\n",
        "\n",
        "    return unicas\n",
        "\n",
        "def n_palavras_diferentes(nova_lista_palavras):\n",
        "\n",
        "    freq = dict()\n",
        "    for palavra in nova_lista_palavras:\n",
        "        p = palavra.lower()\n",
        "        if p in freq:\n",
        "            freq[p] += 1\n",
        "        else:\n",
        "            freq[p] = 1\n",
        "\n",
        "    return len(freq)\n",
        "\n",
        "def compara_assinatura(as_a, as_b):\n",
        "\n",
        "    S = 0\n",
        "    for i in range (0, 6): #i vai de 0 a 5 = 6 traços linguísticos\n",
        "        S = S+ (abs(as_a[i] - as_b[i]))\n",
        "    grau = S/6\n",
        "    if grau < 0:\n",
        "        grau = grau * (-1)\n",
        "    return grau\n",
        "    pass\n",
        "\n",
        "\n",
        "def calcula_assinatura(texto):\n",
        "\n",
        "    lista_de_palavras = separa_palavras(texto)\n",
        "    nova_lista_palavras = []\n",
        "    for x in lista_de_palavras:\n",
        "        item = x\n",
        "        for y in ['.', ',', ':',';']:\n",
        "            item = item.replace(y, \"\")\n",
        "        nova_lista_palavras.append(item)\n",
        "\n",
        "    n_total_palavras = len(nova_lista_palavras)\n",
        "\n",
        "    tamanho_palavras = 0\n",
        "    for i in range (n_total_palavras):\n",
        "        tamanho_palavras = tamanho_palavras + len(nova_lista_palavras[i])\n",
        "        \n",
        "    tamanho_medio_palavra = tamanho_palavras/n_total_palavras\n",
        "    type_token = n_palavras_diferentes(nova_lista_palavras)/n_total_palavras\n",
        "    hapax_legomana = n_palavras_unicas(nova_lista_palavras)/n_total_palavras\n",
        "\n",
        "    tamanho_sentenca = separa_sentencas(texto)\n",
        "    tamanho_caracter_sentenca = 0\n",
        "    for i in range(len(tamanho_sentenca)):\n",
        "        tamanho_caracter_sentenca = tamanho_caracter_sentenca + len(tamanho_sentenca[i])\n",
        "\n",
        "    n_total_sentencas = len(separa_sentencas(texto))\n",
        "\n",
        "    i = 0\n",
        "    frases = []\n",
        "    sentencas = separa_sentencas(texto)\n",
        "    while i < len(sentencas):\n",
        "        frases = frases + separa_frases(sentencas[i])\n",
        "        i += 1\n",
        "    \n",
        "    n_total_frases = len(frases)\n",
        "\n",
        "    tamanho_frase = frases\n",
        "    tamanho_caracter_frase = 0\n",
        "    for i in range(len(tamanho_frase)):\n",
        "        tamanho_caracter_frase = tamanho_caracter_frase + len(tamanho_frase[i])    \n",
        "    \n",
        "    tamanho_medio_sentenca = tamanho_caracter_sentenca/n_total_sentencas\n",
        "    complexidade_sentenca = n_total_frases/n_total_sentencas\n",
        "    tamanho_medio_frase = tamanho_caracter_frase/n_total_frases\n",
        "    assinatura = [tamanho_medio_palavra, type_token, hapax_legomana, tamanho_medio_sentenca, complexidade_sentenca, tamanho_medio_frase]\n",
        "\n",
        "    return assinatura\n",
        "    pass\n",
        "\n",
        "def avalia_textos(textos,ass_cp):\n",
        "    \n",
        "    valor = ass_cp[0]\n",
        "    for x in range(len(ass_cp)):\n",
        "        if ass_cp[x] < valor:\n",
        "            valor = ass_cp[x]\n",
        "            indice = x\n",
        "    return indice\n",
        "\n",
        "def main():\n",
        "    assinatura_principal = le_assinatura()\n",
        "    textos = le_textos()\n",
        "    assinaturas = []\n",
        "    for texto in textos:\n",
        "        assinaturas.append(calcula_assinatura(texto))\n",
        "\n",
        "    assinaturas_comparadas = []\n",
        "    for assinatura in assinaturas:\n",
        "        assinaturas_comparadas.append(compara_assinatura(assinatura_principal, assinatura))\n",
        "\n",
        "    infectado = avalia_textos(textos, assinaturas_comparadas)\n",
        "    print(\"O autor do texto\", infectado, \"está infectado com COH-PIAH.\")\n",
        "\n",
        "main()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}